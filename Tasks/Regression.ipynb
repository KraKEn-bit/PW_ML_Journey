{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1) What is Simple Linear Regression?**\n",
        "Simple Linear Regression is a statistical method used to model the relationship between a **dependent variable (Y)** and a **single independent variable (X)** using a straight line:\n",
        "**Y = mX + c**\n",
        "\n",
        "---\n",
        "\n",
        "**2) What are the key assumptions of Simple Linear Regression?**\n",
        "\n",
        "* Linearity: The relationship between X and Y is linear.\n",
        "* Independence: Observations are independent.\n",
        "* Homoscedasticity: Constant variance of residuals.\n",
        "* Normality: Residuals are normally distributed.\n",
        "* No multicollinearity (though with 1 variable, it doesn't apply here).\n",
        "\n",
        "---\n",
        "\n",
        "**3) What does the coefficient `m` represent in the equation Y = mX + c?**\n",
        "The coefficient `m` is the **slope** of the line, representing the **change in Y for a one-unit increase in X**.\n",
        "\n",
        "---\n",
        "\n",
        "**4) What does the intercept `c` represent in the equation Y = mX + c?**\n",
        "The intercept `c` is the value of Y when X = 0. It represents the **starting point** or **baseline** of the model.\n",
        "\n",
        "---\n",
        "\n",
        "**5) How do we calculate the slope `m` in Simple Linear Regression?**\n",
        "Using the formula:\n",
        "**m = Œ£((X - XÃÑ)(Y - »≤)) / Œ£((X - XÃÑ)¬≤)**\n",
        "\n",
        "---\n",
        "\n",
        "**6) What is the purpose of the least squares method in Simple Linear Regression?**\n",
        "To **minimize the sum of squared errors (residuals)** between the predicted values and actual data points.\n",
        "\n",
        "---\n",
        "\n",
        "**7) How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression?**\n",
        "R¬≤ measures how well the model explains the variance in the target variable.\n",
        "\n",
        "* R¬≤ = 1 ‚Üí Perfect fit\n",
        "* R¬≤ = 0 ‚Üí No explanatory power\n",
        "\n",
        "---\n",
        "\n",
        "### üìô **Multiple Linear Regression**\n",
        "\n",
        "**8) What is Multiple Linear Regression?**\n",
        "A regression model that uses **two or more independent variables** to predict a dependent variable.\n",
        "**Y = b‚ÇÄ + b‚ÇÅX‚ÇÅ + b‚ÇÇX‚ÇÇ + ... + bnXn**\n",
        "\n",
        "---\n",
        "\n",
        "**9) What is the main difference between Simple and Multiple Linear Regression?**\n",
        "\n",
        "* Simple Linear Regression: 1 independent variable\n",
        "* Multiple Linear Regression: 2 or more independent variables\n",
        "\n",
        "---\n",
        "\n",
        "**10) What are the key assumptions of Multiple Linear Regression?**\n",
        "\n",
        "* Linearity\n",
        "* Independence of errors\n",
        "* Homoscedasticity\n",
        "* Normality of residuals\n",
        "* No multicollinearity among predictors\n",
        "\n",
        "---\n",
        "\n",
        "**11) What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?**\n",
        "Heteroscedasticity occurs when the **variance of residuals is not constant** across all levels of the independent variables.\n",
        "It leads to **inefficient estimates** and incorrect standard errors, which can distort hypothesis tests.\n",
        "\n",
        "---\n",
        "\n",
        "**12) How can you improve a Multiple Linear Regression model with high multicollinearity?**\n",
        "\n",
        "* Remove highly correlated predictors\n",
        "* Use **Principal Component Analysis (PCA)**\n",
        "* Apply **Ridge or Lasso Regression**\n",
        "* Combine correlated variables\n",
        "\n",
        "---\n",
        "\n",
        "**13) What are some common techniques for transforming categorical variables for use in regression models?**\n",
        "\n",
        "* **One-Hot Encoding**\n",
        "* **Label Encoding**\n",
        "* **Ordinal Encoding**\n",
        "* **Binary Encoding**\n",
        "\n",
        "---\n",
        "\n",
        "**14) What is the role of interaction terms in Multiple Linear Regression?**\n",
        "Interaction terms (e.g., `X1*X2`) capture **combined effects** of variables that are not explained individually.\n",
        "\n",
        "---\n",
        "\n",
        "**15) How can the interpretation of intercept differ between Simple and Multiple Linear Regression?**\n",
        "\n",
        "* Simple: `c` is the expected Y when X = 0.\n",
        "* Multiple: Intercept represents Y when **all independent variables = 0**, which may or may not be meaningful.\n",
        "\n",
        "---\n",
        "\n",
        "**16) What is the significance of the slope in regression analysis, and how does it affect predictions?**\n",
        "A slope shows the **magnitude and direction** of the relationship. Positive slope = increase in Y with X; negative = decrease.\n",
        "\n",
        "---\n",
        "\n",
        "**17) How does the intercept in a regression model provide context for the relationship between variables?**\n",
        "It provides a **reference point** for prediction ‚Äî the expected value of Y when all Xs are zero.\n",
        "\n",
        "---\n",
        "\n",
        "**18) What are the limitations of using R¬≤ as a sole measure of model performance?**\n",
        "\n",
        "* It can be **misleading with many predictors**\n",
        "* Doesn't tell about **model bias or overfitting**\n",
        "* Can be **artificially high** in complex models\n",
        "  Use **Adjusted R¬≤, RMSE, or cross-validation** for better assessment.\n",
        "\n",
        "---\n",
        "\n",
        "**19) How would you interpret a large standard error for a regression coefficient?**\n",
        "It means the **coefficient estimate is unstable**, indicating weak or uncertain relationship with the target variable.\n",
        "\n",
        "---\n",
        "\n",
        "**20) How can heteroscedasticity be identified in residual plots, and why is it important to address it?**\n",
        "\n",
        "* Identified when residuals **fan out or funnel** in a plot.\n",
        "* It violates model assumptions and affects **validity of confidence intervals** and p-values.\n",
        "\n",
        "---\n",
        "\n",
        "**21) What does it mean if a Multiple Linear Regression model has a high R¬≤ but low adjusted R¬≤?**\n",
        "It means **some predictors are not useful**, and the model may be **overfitting**. Adjusted R¬≤ penalizes extra, unnecessary predictors.\n",
        "\n",
        "---\n",
        "\n",
        "**22) Why is it important to scale variables in Multiple Linear Regression?**\n",
        "\n",
        "* Prevents **large-valued features** from dominating\n",
        "* Important for **regularization techniques** (Ridge, Lasso)\n",
        "* Helps interpret coefficients more clearly\n",
        "\n",
        "---\n",
        "\n",
        "### üìó **Polynomial Regression**\n",
        "\n",
        "**23) What is Polynomial Regression?**\n",
        "Polynomial regression models **nonlinear relationships** by adding powers of the independent variable:\n",
        "**Y = b‚ÇÄ + b‚ÇÅX + b‚ÇÇX¬≤ + ... + bnX‚Åø**\n",
        "\n",
        "---\n",
        "\n",
        "**24) How does polynomial regression differ from linear regression?**\n",
        "\n",
        "* Linear Regression fits a **straight line**\n",
        "* Polynomial Regression fits a **curved line** by including powers of X\n",
        "\n",
        "---\n",
        "\n",
        "**25) When is polynomial regression used?**\n",
        "When data shows a **non-linear** pattern that cannot be captured with a straight line.\n",
        "\n",
        "---\n",
        "\n",
        "**26) What is the general equation for polynomial regression?**\n",
        "**Y = b‚ÇÄ + b‚ÇÅX + b‚ÇÇX¬≤ + b‚ÇÉX¬≥ + ... + bnX‚Åø**\n",
        "\n",
        "---\n",
        "\n",
        "**27) Can polynomial regression be applied to multiple variables?**\n",
        "Yes, it becomes **Multivariate Polynomial Regression**, using polynomial terms of multiple variables and their interactions.\n",
        "\n",
        "---\n",
        "\n",
        "**28) What are the limitations of polynomial regression?**\n",
        "\n",
        "* Can **overfit** easily\n",
        "* Becomes **complex** with higher degrees\n",
        "* Sensitive to **outliers**\n",
        "* Harder to interpret\n",
        "\n",
        "---\n",
        "\n",
        "**29) What methods can be used to evaluate model fit when selecting the degree of a polynomial?**\n",
        "\n",
        "* **Cross-validation**\n",
        "* **Adjusted R¬≤**\n",
        "* **AIC/BIC** (information criteria)\n",
        "* **Plot residuals** and test overfitting\n",
        "\n",
        "---\n",
        "\n",
        "**30) Why is visualization important in polynomial regression?**\n",
        "Helps in **understanding curvature**, detecting **overfitting**, and ensuring the model fits data intuitively.\n",
        "\n",
        "---\n",
        "\n",
        "**31) How is polynomial regression implemented in Python?**\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Example: Polynomial Regression of degree 3\n",
        "model = make_pipeline(PolynomialFeatures(degree=3), LinearRegression())\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "A9BDZoZyJ8Ib"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD_elpaJJ6wl"
      },
      "outputs": [],
      "source": []
    }
  ]
}

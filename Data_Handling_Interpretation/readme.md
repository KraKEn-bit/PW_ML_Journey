### **This covers essential data preprocessing and modeling techniques, including feature extraction, missing value handling, imbalanced dataset treatment, data scaling, encoding, and concepts related to underfitting and overfitting.** 

# Data Handling & Feature Engineering

This folder contains hands-on implementations of **data preprocessing, cleaning, and feature engineering techniques** commonly used in Machine Learning pipelines.

All notebooks were created while following a structured Machine Learning course, with a focus on understanding *why* each step is needed and *how* it affects model performance.

## Topics Covered

### 1. Handling Missing Values
- Identifying missing data
- Mean / median / mode imputation
- Understanding impact of missing values on models

ðŸ“„ `Handling_Missing_Values.ipynb`

### 2. Outlier Treatment
- Detecting outliers using statistical methods
- Removing vs capping outliers
- Effect of outliers on model stability

ðŸ“„ `Outlier_Treatment.ipynb`

### 3. Data Encoding
- Label Encoding
- One-Hot Encoding
- Handling categorical variables for ML models

ðŸ“„ `DataEncoding.ipynb`

### 4. Feature Extraction & Feature Selection
- Creating meaningful features
- Selecting relevant features
- Reducing dimensionality and noise

ðŸ“„ `Feature_Extraction_Selection.ipynb`

### 5. Class Imbalance Handling
- Understanding imbalanced datasets
- Techniques such as resampling
- Why accuracy is misleading for imbalanced data

ðŸ“„ `Class_imbalance_Handling.ipynb`

## Objective
To build a strong foundation in **data preprocessing and feature engineering**, which are critical steps before training any Machine Learning model.


## Notes
These notebooks are part of my **Machine Learning learning journey** and focus on conceptual clarity and correct implementation rather than production-level optimization.
